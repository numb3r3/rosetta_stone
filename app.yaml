bert: &bert
  model_package: rosetta.models.pretrained_bert
  model_class: PretrainedBert
  dataio_package: rosetta.datasets.text.masked_text
  dataio_class: MaskedTextDataIO

  train_files:
    - ./tests/test_data/sonnets.txt
  
  eval_files:
    - ./tests/test_data/sonnets.txt

  bert_config_file: ./examples/bert/config.json
  tokenizer_name: bert-base-cased
  
  hidden_size: 768
  vocab_size: 30522
  
  num_epochs: 100

resnet56: &resnet56
  model_package: examples.vision.resnet_model
  model_class: ResNet
  dataio_package: rosetta.datasets.vision.cifar10
  dataio_class: CIFAR10

  batch_size: 256
  
  n_size: 9
  num_classes: 10

lasnet: &lasnet
  model_package: examples.speech.las_model
  model_class: LASNet

  dataio_package: rosetta.datasets.speech.aishell
  dataio_class: AiShellDataIO

  data_path: /workspace/cpfs-data/datasets/open_speech_data/aishell/data_aishell
  # tokenizer_name_or_path: bert-base-chinese
  tokenizer_name_or_path: /workspace/cpfs-data/models/reberta_zh_l12_pytorch/vocab.txt

  log_dir_prefix: /workspace/cpfs-data/logs

  audio_config: # Attributes of audio feature
    feat_type: 'fbank'
    feat_dim:  40
    frame_length: 25                      # ms
    frame_shift: 10                       # ms
    dither: 0                             # random dither audio, 0: no dither
    apply_cmvn: True
    delta_order: 2                        # 0: do nothing, 1: add delta, 2: add delta and accelerate
    delta_window_size: 2
  
  encoder_config:
    prenet: 'vgg'                         # 'vgg'/'cnn'/''
    # vgg: True                             # 4x reduction on time feature extraction
    module: 'GRU'                        # 'LSTM'/'GRU'/'Transformer'
    bidirection: True
    dim: [512,512,512]
    dropout: [0.1,0.1,0.1]
    layer_norm: [False,False,False]
    proj: [True,True,True]      # Linear projection + Tanh after each rnn layer
    sample_rate: [1,1,1]
    sample_style: 'drop'                  # 'drop'/'concat'

  attention_config:
    mode: 'loc'                           # 'dot'/'loc'
    dim: 300
    num_head: 1
    v_proj: False                         # if False and num_head>1, encoder state will be duplicated for each head
    temperature: 0.5                      # scaling factor for attention
    loc_kernel_size: 100                  # just for mode=='loc'
    loc_kernel_num: 10                    # just for mode=='loc'

  decoder_config:
    module: 'LSTM'                        # 'LSTM'/'GRU'/'Transformer'
    dim: 512
    layer: 1
    dropout: 0.1

  ctc_weight: 0.3
  input_size: 120
  batch_size: 32
  
  learning_rate: 5e-5